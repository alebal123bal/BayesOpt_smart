{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f727f8f3",
   "metadata": {},
   "source": [
    "# Multi-Objective Bayesian Optimization Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide to understanding and using the high-performance multi-objective Bayesian optimization implementation.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Theory Overview](#theory-overview)\n",
    "3. [Implementation Features](#implementation-features)\n",
    "4. [Basic Usage](#basic-usage)\n",
    "5. [Advanced Configuration](#advanced-configuration)\n",
    "6. [Visualization & Analysis](#visualization--analysis)\n",
    "7. [Performance Tips](#performance-tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d68c6a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Bayesian Optimization (BO) is a powerful technique for optimizing expensive-to-evaluate functions. This implementation focuses on **multi-objective optimization** where we want to optimize multiple competing objectives simultaneously.\n",
    "\n",
    "### Key Features:\n",
    "- ğŸš€ **High Performance**: Numba-accelerated computations\n",
    "- ğŸ¯ **Multi-Objective**: Optimize multiple objectives simultaneously\n",
    "- ğŸ“Š **Rich Visualization**: Interactive heatmaps and Pareto analysis\n",
    "- ğŸ”§ **Flexible**: Customizable hyperparameters and acquisition functions\n",
    "- ğŸ“ˆ **Batch Optimization**: Evaluate multiple points per iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b2dcf",
   "metadata": {},
   "source": [
    "## Theory Overview\n",
    "\n",
    "### Gaussian Process Regression\n",
    "The core of Bayesian optimization is modeling the objective function(s) using Gaussian Processes (GPs):\n",
    "\n",
    "$$f(x) \\sim \\mathcal{GP}(\\mu(x), k(x, x'))$$\n",
    "\n",
    "Where:\n",
    "- $\\mu(x)$ is the mean function (prior belief about function values)\n",
    "- $k(x, x')$ is the kernel function (models similarity between points)\n",
    "\n",
    "### RBF Kernel\n",
    "We use the Radial Basis Function (RBF) kernel:\n",
    "\n",
    "$$k(x, x') = \\sigma^2 \\exp\\left(-\\frac{||x - x'||^2}{2\\ell^2}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $\\sigma^2$ is the signal variance (`prior_variance`)\n",
    "- $\\ell$ is the length scale (`length_scales`)\n",
    "\n",
    "### Multi-Objective Acquisition\n",
    "We use Upper Confidence Bound (UCB) for each objective:\n",
    "\n",
    "$$\\text{UCB}(x) = \\mu(x) + \\beta \\sigma(x)$$\n",
    "\n",
    "The final acquisition function combines all objectives:\n",
    "\n",
    "$$\\text{Acquisition}(x) = \\sum_{i=1}^{m} \\text{UCB}_i(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5fa21",
   "metadata": {},
   "source": [
    "## Implementation Features\n",
    "\n",
    "### Core Components:\n",
    "\n",
    "1. **Latin Hypercube Sampling (LHS)**: Efficient initial sampling\n",
    "2. **Parallel Kernel Computation**: Fast GP operations with Numba\n",
    "3. **Hyperparameter Optimization**: Automatic tuning via MLL maximization\n",
    "4. **Batch Point Selection**: Evaluate multiple points per iteration\n",
    "5. **Pareto Analysis**: Find optimal trade-offs between objectives\n",
    "\n",
    "### Performance Optimizations:\n",
    "- **Numba JIT compilation** for critical functions\n",
    "- **Parallel kernel matrix computation**\n",
    "- **Memory-efficient matrix operations**\n",
    "- **Intelligent caching and reuse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940385cd",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Let's start with a simple example using the built-in toy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48cde5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from bayesopt import BayesianOptimization\n",
    "from bayesopt.callbacks import (\n",
    "    PlotterCallback,\n",
    "    ProgressLogger,\n",
    "    GraphSaverCallback,\n",
    "    PerformanceMonitor,\n",
    "    OptimizationLogger,\n",
    ")\n",
    "from examples.benchmark_functions import toy_function\n",
    "from plotting import PyQtPlotter, StaticPlotter\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20a4e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Graph saver initialized. Saving to: outputs\\figures\\run_20260215_191820\n"
     ]
    }
   ],
   "source": [
    "# Define bounds for the search space\n",
    "X_MAX = 300\n",
    "Y_MAX = 300\n",
    "\n",
    "# Note: Upper bounds are EXCLUSIVE (300 means 0-299 inclusive)\n",
    "bounds = [\n",
    "    (0, X_MAX),  # x dimension: 0 to 299\n",
    "    (0, Y_MAX),  # y dimension: 0 to 299\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize PyQtGraph Plotter (fast, OpenGL-accelerated)\n",
    "plotter = PyQtPlotter(\n",
    "    bounds=bounds,\n",
    "    n_objectives=len(bounds),\n",
    ")\n",
    "\n",
    "# Setup callbacks\n",
    "plotter_callback = PlotterCallback(plotter)\n",
    "\n",
    "progress_logger = ProgressLogger(\n",
    "    log_file=\"outputs/logs/optimization.log\", verbose=True\n",
    ")\n",
    "\n",
    "performance_logger = PerformanceMonitor()\n",
    "\n",
    "optimization_logger = OptimizationLogger()\n",
    "\n",
    "graph_saver = GraphSaverCallback(\n",
    "    plotter_class=StaticPlotter,\n",
    "    bounds=bounds,\n",
    "    n_objectives=len(bounds),\n",
    "    save_every=1,\n",
    "    save_format=\"png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942d981",
   "metadata": {},
   "source": [
    "### Create and Run the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afab7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer with callbacks\n",
    "optimizer = BayesianOptimization(\n",
    "    toy_function,\n",
    "    bounds,\n",
    "    n_objectives=len(bounds),\n",
    "    initial_samples=(X_MAX + Y_MAX) // 100,  # 1% of grid size\n",
    "    n_iterations=15,\n",
    "    batch_size=X_MAX // 100,  # 1% of grid size\n",
    "    betas=np.array([2.0] * len(bounds)),\n",
    "    callbacks=[\n",
    "        # plotter_callback,\n",
    "        progress_logger,\n",
    "        optimization_logger,\n",
    "        performance_logger,\n",
    "        graph_saver,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f870766c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting optimization...\n",
      "\n",
      "  â””â”€ Iter 6: Evaluated 9 point(s)\n",
      "      Point 1: x=[292.,204.] â†’ objectives=[-20064., -2896.]\n",
      "      Point 2: x=[182., 65.] â†’ objectives=[ -924.,-7205.]\n",
      "      Point 3: x=[223.,198.] â†’ objectives=[-5229.,-2284.]\n",
      "      Point 4: x=[ 93.,118.] â†’ objectives=[-3149.,-1004.]\n",
      "      Point 5: x=[107.,296.] â†’ objectives=[ -1749.,-21296.]\n",
      "      Point 6: x=[44.,33.] â†’ objectives=[-11136.,-13669.]\n",
      "      Point 7: x=[146.,154.] â†’ objectives=[84., 4.]\n",
      "      Point 8: x=[146.,155.] â†’ objectives=[84.,-5.]\n",
      "      Point 9: x=[145.,155.] â†’ objectives=[75.,-5.]\n",
      "     Best so far: obj0=84.0000 at [146.,154.], obj1=4.0000 at [146.,154.] â­ NEW BEST [obj0,obj1] (0.050s)\n",
      "\n",
      "ğŸ”„ Iteration 6 (n_evaluations=9)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0163s | Kernels: 0.0171s | Acquisition: 0.0169s | Eval: 0.0000s | TOTAL: 0.0503s\n",
      "  ğŸ’¾ Saved plot: iteration_0006.png\n",
      "  â””â”€ Iter 9: Evaluated 3 point(s)\n",
      "      Point 10: x=[  0.,186.] â†’ objectives=[-22400., -1276.]\n",
      "      Point 11: x=[  0.,185.] â†’ objectives=[-22400., -1205.]\n",
      "      Point 12: x=[  0.,187.] â†’ objectives=[-22400., -1349.]\n",
      "     Best so far: obj0=84.0000 at [146.,154.], obj1=4.0000 at [146.,154.] (0.039s)\n",
      "\n",
      "ğŸ”„ Iteration 9 (n_evaluations=12)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0127s | Kernels: 0.0114s | Acquisition: 0.0144s | Eval: 0.0000s | TOTAL: 0.0385s\n",
      "  ğŸ’¾ Saved plot: iteration_0009.png\n",
      "  â””â”€ Iter 12: Evaluated 3 point(s)\n",
      "      Point 13: x=[299.,  0.] â†’ objectives=[-22101.,-22480.]\n",
      "      Point 14: x=[298.,  0.] â†’ objectives=[-21804.,-22480.]\n",
      "      Point 15: x=[299.,  1.] â†’ objectives=[-22101.,-22181.]\n",
      "     Best so far: obj0=84.0000 at [146.,154.], obj1=4.0000 at [146.,154.] (0.031s)\n",
      "\n",
      "ğŸ”„ Iteration 12 (n_evaluations=15)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0077s | Kernels: 0.0079s | Acquisition: 0.0150s | Eval: 0.0000s | TOTAL: 0.0307s\n",
      "  ğŸ’¾ Saved plot: iteration_0012.png\n",
      "  â””â”€ Iter 15: Evaluated 3 point(s)\n",
      "      Point 16: x=[205.,132.] â†’ objectives=[-2925., -304.]\n",
      "      Point 17: x=[204.,132.] â†’ objectives=[-2816., -304.]\n",
      "      Point 18: x=[204.,133.] â†’ objectives=[-2816., -269.]\n",
      "     Best so far: obj0=84.0000 at [146.,154.], obj1=4.0000 at [146.,154.] (0.040s)\n",
      "\n",
      "ğŸ”„ Iteration 15 (n_evaluations=18)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0103s | Kernels: 0.0111s | Acquisition: 0.0182s | Eval: 0.0000s | TOTAL: 0.0397s\n",
      "  ğŸ’¾ Saved plot: iteration_0015.png\n",
      "  â””â”€ Iter 18: Evaluated 3 point(s)\n",
      "      Point 19: x=[150.,150.] â†’ objectives=[100., 20.]\n",
      "      Point 20: x=[150.,151.] â†’ objectives=[100., 19.]\n",
      "      Point 21: x=[149.,150.] â†’ objectives=[99.,20.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] â­ NEW BEST [obj0,obj1] (0.051s)\n",
      "\n",
      "ğŸ”„ Iteration 18 (n_evaluations=21)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0120s | Kernels: 0.0156s | Acquisition: 0.0231s | Eval: 0.0000s | TOTAL: 0.0508s\n",
      "  ğŸ’¾ Saved plot: iteration_0018.png\n",
      "  â””â”€ Iter 21: Evaluated 3 point(s)\n",
      "      Point 22: x=[157.,151.] â†’ objectives=[51.,19.]\n",
      "      Point 23: x=[152.,147.] â†’ objectives=[96.,11.]\n",
      "      Point 24: x=[149.,156.] â†’ objectives=[ 99.,-16.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.047s)\n",
      "\n",
      "ğŸ”„ Iteration 21 (n_evaluations=24)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0114s | Kernels: 0.0131s | Acquisition: 0.0224s | Eval: 0.0000s | TOTAL: 0.0469s\n",
      "  ğŸ’¾ Saved plot: iteration_0021.png\n",
      "  â””â”€ Iter 24: Evaluated 3 point(s)\n",
      "      Point 25: x=[144.,148.] â†’ objectives=[64.,16.]\n",
      "      Point 26: x=[155.,149.] â†’ objectives=[75.,19.]\n",
      "      Point 27: x=[152.,150.] â†’ objectives=[96.,20.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.051s)\n",
      "\n",
      "ğŸ”„ Iteration 24 (n_evaluations=27)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0123s | Kernels: 0.0149s | Acquisition: 0.0241s | Eval: 0.0000s | TOTAL: 0.0512s\n",
      "  ğŸ’¾ Saved plot: iteration_0024.png\n",
      "  â””â”€ Iter 27: Evaluated 3 point(s)\n",
      "      Point 28: x=[149.,152.] â†’ objectives=[99.,16.]\n",
      "      Point 29: x=[162.,155.] â†’ objectives=[-44., -5.]\n",
      "      Point 30: x=[147.,149.] â†’ objectives=[91.,19.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.057s)\n",
      "\n",
      "ğŸ”„ Iteration 27 (n_evaluations=30)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0130s | Kernels: 0.0172s | Acquisition: 0.0267s | Eval: 0.0000s | TOTAL: 0.0568s\n",
      "  ğŸ’¾ Saved plot: iteration_0027.png\n",
      "  â””â”€ Iter 30: Evaluated 3 point(s)\n",
      "      Point 31: x=[145.,153.] â†’ objectives=[75.,11.]\n",
      "      Point 32: x=[169.,149.] â†’ objectives=[-261.,  19.]\n",
      "      Point 33: x=[146.,146.] â†’ objectives=[84., 4.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.063s)\n",
      "\n",
      "ğŸ”„ Iteration 30 (n_evaluations=33)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0130s | Kernels: 0.0191s | Acquisition: 0.0308s | Eval: 0.0000s | TOTAL: 0.0630s\n",
      "  ğŸ’¾ Saved plot: iteration_0030.png\n",
      "  â””â”€ Iter 33: Evaluated 3 point(s)\n",
      "      Point 34: x=[141.,153.] â†’ objectives=[19.,11.]\n",
      "      Point 35: x=[163.,165.] â†’ objectives=[ -69.,-205.]\n",
      "      Point 36: x=[144.,141.] â†’ objectives=[ 64.,-61.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.069s)\n",
      "\n",
      "ğŸ”„ Iteration 33 (n_evaluations=36)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0157s | Kernels: 0.0197s | Acquisition: 0.0336s | Eval: 0.0000s | TOTAL: 0.0690s\n",
      "  ğŸ’¾ Saved plot: iteration_0033.png\n",
      "  â””â”€ Iter 36: Evaluated 3 point(s)\n",
      "      Point 37: x=[136.,144.] â†’ objectives=[-96.,-16.]\n",
      "      Point 38: x=[160.,134.] â†’ objectives=[   0.,-236.]\n",
      "      Point 39: x=[155.,131.] â†’ objectives=[  75.,-341.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.068s)\n",
      "\n",
      "ğŸ”„ Iteration 36 (n_evaluations=39)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0085s | Kernels: 0.0237s | Acquisition: 0.0359s | Eval: 0.0000s | TOTAL: 0.0682s\n",
      "  ğŸ’¾ Saved plot: iteration_0036.png\n",
      "  â””â”€ Iter 39: Evaluated 3 point(s)\n",
      "      Point 40: x=[151.,158.] â†’ objectives=[ 99.,-44.]\n",
      "      Point 41: x=[153.,147.] â†’ objectives=[91.,11.]\n",
      "      Point 42: x=[137.,143.] â†’ objectives=[-69.,-29.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.079s)\n",
      "\n",
      "ğŸ”„ Iteration 39 (n_evaluations=42)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0160s | Kernels: 0.0244s | Acquisition: 0.0390s | Eval: 0.0000s | TOTAL: 0.0794s\n",
      "  ğŸ’¾ Saved plot: iteration_0039.png\n",
      "  â””â”€ Iter 42: Evaluated 3 point(s)\n",
      "      Point 43: x=[139.,160.] â†’ objectives=[-21.,-80.]\n",
      "      Point 44: x=[153.,165.] â†’ objectives=[  91.,-205.]\n",
      "      Point 45: x=[161.,164.] â†’ objectives=[ -21.,-176.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.081s)\n",
      "\n",
      "ğŸ”„ Iteration 42 (n_evaluations=45)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0113s | Kernels: 0.0252s | Acquisition: 0.0441s | Eval: 0.0000s | TOTAL: 0.0807s\n",
      "  ğŸ’¾ Saved plot: iteration_0042.png\n",
      "  â””â”€ Iter 45: Evaluated 3 point(s)\n",
      "      Point 46: x=[156.,177.] â†’ objectives=[  64.,-709.]\n",
      "      Point 47: x=[145.,144.] â†’ objectives=[ 75.,-16.]\n",
      "      Point 48: x=[154.,151.] â†’ objectives=[84.,19.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.088s)\n",
      "\n",
      "ğŸ”„ Iteration 45 (n_evaluations=48)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0110s | Kernels: 0.0292s | Acquisition: 0.0473s | Eval: 0.0000s | TOTAL: 0.0875s\n",
      "  ğŸ’¾ Saved plot: iteration_0045.png\n",
      "  â””â”€ Iter 48: Evaluated 3 point(s)\n",
      "      Point 49: x=[157.,149.] â†’ objectives=[51.,19.]\n",
      "      Point 50: x=[144.,168.] â†’ objectives=[  64.,-304.]\n",
      "      Point 51: x=[162.,142.] â†’ objectives=[-44.,-44.]\n",
      "     Best so far: obj0=100.0000 at [150.,150.], obj1=20.0000 at [150.,150.] (0.094s)\n",
      "\n",
      "ğŸ”„ Iteration 48 (n_evaluations=51)\n",
      "ğŸ” Selected 3 points for next batch\n",
      "[Timing] Hyperparams: 0.0134s | Kernels: 0.0306s | Acquisition: 0.0498s | Eval: 0.0000s | TOTAL: 0.0937s\n",
      "  ğŸ’¾ Saved plot: iteration_0048.png\n",
      "\n",
      "ğŸ‰ Optimization completed in 21.74 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "start_time = time.time()\n",
    "print(\"ğŸš€ Starting optimization...\\n\")\n",
    "\n",
    "optimizer.optimize()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nğŸ‰ Optimization completed in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3a676",
   "metadata": {},
   "source": [
    "### Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "683bb43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Creating GIF from 15 images...\n",
      "âœ… GIF created: outputs\\figures\\run_20260215_191820\\optimization.gif\n",
      "   Frames: 15 | Duration: 500ms per frame\n",
      "ğŸ“Š Pareto Analysis Results:\n",
      "Input: [150. 150.], Pareto Point 1: [100.  20.]\n",
      "\n",
      "ğŸ“Š Performance Summary:\n",
      "  Total iterations: 15\n",
      "  Average time per iteration: 0.060s\n",
      "  Total time: 0.91s\n",
      "\n",
      "  Breakdown (average):\n",
      "    Hyperparams: 0.0123s (20.4%)\n",
      "    Kernels: 0.0187s (30.9%)\n",
      "    Acquisition: 0.0294s (48.7%)\n",
      "    Evaluation: 0.0000s (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Create animated GIF from saved images\n",
    "graph_saver.finalize()\n",
    "\n",
    "# Analyze results\n",
    "optimizer.pareto_analysis()\n",
    "\n",
    "# Log performance summary\n",
    "performance_logger.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460afb4",
   "metadata": {},
   "source": [
    "## Visualization & Analysis\n",
    "\n",
    "### Understanding the Heatmap Plots\n",
    "\n",
    "When you run the 2D optimization, you'll see heatmap plots with three panels per objective:\n",
    "\n",
    "1. **Mean Prediction (Î¼)**: Shows the GP's prediction of objective values\n",
    "2. **Uncertainty (Ïƒ)**: Shows where the GP is uncertain (high variance)\n",
    "3. **Acquisition Function**: Shows where the optimizer will sample next\n",
    "\n",
    "### Plot Interpretation:\n",
    "- **Dark blue areas** in mean plots indicate low predicted values\n",
    "- **Bright yellow areas** in mean plots indicate high predicted values\n",
    "- **Red areas** in uncertainty plots show high uncertainty\n",
    "- **White circles** show evaluated points\n",
    "- **Red stars** show next points to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1146de2",
   "metadata": {},
   "source": [
    "## Performance Tips\n",
    "\n",
    "### Choosing Parameters\n",
    "\n",
    "#### Initial Samples\n",
    "- **Rule of thumb**: 5-10 samples per dimension\n",
    "- **More samples**: Better initial model, slower startup\n",
    "- **Fewer samples**: Faster startup, more exploration needed\n",
    "\n",
    "#### Batch Size\n",
    "- **Larger batches**: Better parallelization, less adaptive\n",
    "- **Smaller batches**: More adaptive, sequential evaluation\n",
    "- **Sweet spot**: 2-5 points per batch\n",
    "\n",
    "#### Beta Values (Exploration)\n",
    "- **Higher Î²**: More exploration, slower convergence\n",
    "- **Lower Î²**: More exploitation, faster convergence\n",
    "- **Typical range**: 1.0 - 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e56ee3",
   "metadata": {},
   "source": [
    "### Memory and Computation Scaling\n",
    "\n",
    "The algorithm's complexity scales as:\n",
    "- **Memory**: O(nÂ² Â· m) where n = evaluations, m = objectives\n",
    "- **Computation**: O(nÂ³ Â· m) due to matrix inversion\n",
    "\n",
    "**Practical limits**:\n",
    "- Up to ~100-200 evaluations: Excellent performance\n",
    "- 200-500 evaluations: Good performance\n",
    "- 500+ evaluations: Consider reducing `n_iterations` or `batch_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682929a4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "\n",
    "âœ… **Theory**: Gaussian Processes and multi-objective optimization  \n",
    "âœ… **Implementation**: High-performance Numba-accelerated code  \n",
    "âœ… **Usage**: From basic to advanced configurations  \n",
    "âœ… **Visualization**: Understanding heatmaps and Pareto analysis  \n",
    "âœ… **Performance**: Tuning parameters for optimal results  \n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Start simple**: Use default parameters first\n",
    "2. **Understand trade-offs**: Balance exploration vs exploitation\n",
    "3. **Monitor performance**: Watch convergence and Pareto fronts\n",
    "4. **Scale appropriately**: Consider memory limits for large problems\n",
    "\n",
    "Happy optimizing! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
